# Project_Pycuda_LambdaMart
In this project, we decided to work on a Machine-Learned Ranking problem. Machine-Learned Ranking (MLR) or Learning-To-Rank (LTR) is a relatively recent class of techniques in which supervised Machine Learning algorithms are used to learn a ranking function. In particular, it is very important for search engines to choose a precise ranking function because it directly affects the search experience of millions of users. Thus, the MLR turns a search problem into a Machine Learning problem. It is interested in a list of documents, and the goal is to obtain an optimal ranking. The MLR does not focus so much on the exact scores of each document, but rather on the relative order in which these documents must be displayed. Thus, while the most common MLR application is search engine ranking, it can be used anywhere where you need to produce an ordered list of objects.  The training base for such a model consists of a list of documents as well as a score for each of these documents. For a search engine, this corresponds to a list of results associated with a query, as well as a score of relevance of each document associated with the query. The most common way to obtain these relevance ratings is to ask a human expert to manually score results based on queries.  The algorithm we chose to implement and parallelize is the LambdaMART algorithm. We used the PyCuda environment to parallelize it and we used a  GPU. We used the paper from Chris J.C. Burges' paper, From RankNet to LambdaRank to LambdaMART: An Overview (June 23, 2010) to understand the model and to implement it. The final notebook is in french, we present the LambdaMART model and our implementation.
